{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 0\n",
    "\n",
    "Welcome to your first homework! The goal of this assignment is to refresh your memory on probability and provide a crash course on [pandas](https://pandas.pydata.org/), a popular library used for data manipulation and analysis. For those of you who've only had experience with R, the `pandas` library is quite similar to the tools available to us for data manipulation in R so you'll be able to apply the same programming intuition here.\n",
    "\n",
    "Your homework should be completed fully within this Jupyter notebook and **submitted on Gradescope**. If you haven't yet enrolled in the class on Gradescope, you can sign up a this link:\n",
    "\n",
    "[https://www.gradescope.com/courses/170321](https://www.gradescope.com/courses/170321)\n",
    "\n",
    "Access code: **M7RZE7**\n",
    "\n",
    "For a quick introduction to Jupyter notebooks and the different things you can do in them, you can go back to the jupyter intro notebook [here](https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fpublic-health-196%2Fph196-fa20&urlpath=tree%2Fph196-fa20%2Fdiscussion%2Fjupyter_intro.ipynb&branch=master).\n",
    "\n",
    "Submission instructions are at the end of the notebook. If you *absolutely must* complete any parts of this homework outside of this notebook you are responsible for making sure it is uploaded to Gradescope and properly tagged."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Let's get started!**\n",
    "\n",
    "Here are some helpful resources for this assignment:\n",
    "\n",
    "- Our own [CS 61A](https://cs61a.org/) is a wonderful introduction to Python. Their course textbook, [Composing Programs](http://composingprograms.com/), is helpful. We recommend looking at sections 1.2-1.6 and 2.1-2.6.\n",
    "- Data 100 provides a great summary of everything you need to know in their textbook [here](https://www.textbook.ds100.org/ch/03/pandas_intro.html). If you're not familiar with pandas already, we highly recommend giving that a read.\n",
    "- The CS 70 notes are a helpful reference for probability concepts. You might find [Note 14](https://inst.eecs.berkeley.edu/~cs70/fa16/static/notes/n14.pdf) on conditional probability and [Note 16](https://inst.eecs.berkeley.edu/~cs70/fa16/static/notes/n16.pdf) on expectation especially helpful for this assignment.\n",
    "\n",
    "More resources are available in our classwide [resource sheet](https://piazza.com/class/ke4s2oyrb3z6wa?cid=7).\n",
    "\n",
    "Your GSI is here to support you! Please feel free to ask questions at office hours or on Piazza. **However, if you are posting code, please make your Piazza question private.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries. Run this cell\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Initialize OK - this is for sanity checking\n",
    "from client.api.notebook import Notebook\n",
    "ok = Notebook('hw0.ok')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring Data\n",
    "\n",
    "In this assignment, we'll be working with the `framingham` dataset from a comprehensive cardiovascular study. We've taken a sample from the full dataset and provided it to you in the file `framingham_sample.csv`.\n",
    "\n",
    "**Question 1.** Let's first import the dataset. Set `framingham` to a DataFrame containing the data from `framingham_sample.csv`, then view the first five rows of the DataFrame. \n",
    "\n",
    "*Hint 1:* Use the function `pd.read_csv()` to read in the file.\n",
    "\n",
    "*Hint 2:* To view the first five rows of `framingham`, you can use `framingham.head()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "framingham = ...\n",
    "# View the first 5 rows"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following cell to run some test cases that check your answer. You should treat these tests as sanity checks to make sure you're moving in the right direction. If you have the wrong answer, some of the tests will give you hints. If you pass the sanity checks you can be pretty confident you will get full credit on a problem. There aren't any tricky hidden test cases. We will lightly review code since not all the tests check for full correctness."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add an argument to `head()` to view a different number of rows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framingham.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2.** We're interested in seeing how much data we have. Assign `num_rows` and `num_columns` to the number of rows and columns in `framingham`, respectively.\n",
    "\n",
    "*Hint:* A DataFrame's `shape` attribute gives you a useful tuple. Notice that syntactically, an **attribute** does not need the parentheses, unlike a **function**, which does (e.g. the `head()` function requires the parentheses).\n",
    "\n",
    "*Hint 2:* You can assign multiple variables (also called \"unpacking\") from a single tuple like so: `x, y = (3, 5)` will use the tuple `(3, 5)` to assign `x = 3` and `y = 5`. (See section [2.4.2](http://composingprograms.com/pages/24-mutable-data.html#sequence-objects) of Composing Programs for more information about tuples.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows, num_columns = ...\n",
    "num_rows, num_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3.** Let us now take a deeper look at the columns. Assign `columns_list` to a list that contain the `framingham` column names as strings.\n",
    "\n",
    "*Hint:* Use the `columns` attribute of the DataFrame. You will have to convert the variable type of the result as a `list` (also known as *casting*). For example, you can cast an integer `x = 3` to be a `string` with `str(x)` (which has the value `\"3\"`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_list = ...\n",
    "columns_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade('q3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4.** We can quickly see a summary of the data using the `describe()` function. Try it out below:\n",
    "\n",
    "*Hint:* This is similar to the `head()` function we used above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try out describe() here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the output of the `describe()` function. Comment on any problems you see or questions you have. Refer to the documentation in `framdoc.pdf` [here](https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fpublic-health-196%2Fph196-fa20&urlpath=tree%2Fph196-fa20%2Fhw0%2Fframdoc.pdf&branch=master) to understand what the columns mean.\n",
    "\n",
    "What is the `count` row and why are some values in this row less than others?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer in this cell*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accessing Data\n",
    "\n",
    "Now that we've imported our data into Pandas, it's time to explore our DataFrame. We'll learn how to access our data in various ways.\n",
    "\n",
    "**Question 5.** Set `person_age` to the age of the subject corresponding to the 0th row of `framingham` using the `.loc` notation.\n",
    "\n",
    "*Hint:* The syntax should be something like `framingham.loc[..., ...]` (where you fill in the `...`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "person_age = ...\n",
    "person_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists are a very useful data structure in Python. They hold, well, a list of values:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "produce = [\"apple\", \"carrot\", \"broccoli\"]\n",
    "produce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lists in Python are zero-indexed (i.e. the first element has index 0):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fruit = produce[0]\n",
    "fruit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can access parts of the list with a *slicing* operator:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "veggies = produce[1:3]\n",
    "veggies"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To slice a list, we use the notation `lst[start:end]`. Notice that when we slice lists, the `start` index is included, but the `end` index is excluded. That's why to select element 2, we need the `end` index to have value 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6.** Set `small_data` to a new DataFrame that includes the `RANDID`, `TOTCHOL`, and `AGE` columns of the first 10 rows in `framingham`.\n",
    "\n",
    "*Hint 1:* Be careful! `.loc` slicing includes the start and end indices, so to select the first 3 rows of `framingham`, you can use the syntax `framingham.loc[0:2,...]`. \n",
    "\n",
    "*Hint 2:* You can select multiple columns by providing a list of column names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = ...\n",
    "small_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q6\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also select columns simply like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "framingham[\"AGE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's learn how to *filter*, or add conditions, to our data. For example, let's say we're only interested in subjects who are 50 years or older.\n",
    "\n",
    "**Question 7.** Set `over_50` to a new DataFrame that only includes rows from `framingham` corresponding to subjects who are 50 years or older.\n",
    "\n",
    "_Hint:_ The syntax should look something like `framingham[framingham[...]...]` (where you fill in the `...`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "over_50 = ...\n",
    "over_50.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q7\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8.** What is the range (`max` - `min`) of ages in `framingham`? Assign this number to `age_range`.\n",
    "\n",
    "*Hint:* Use the `np.max()` and `np.min()` functions on a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_range = ...\n",
    "age_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q8\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There's a shortcut method to do this: `np.ptp`. You can find out more information about a function by pressing `Shift+Tab` while your cursor is inside the function (inside the parentheses). Repeatedly pressing will provide more and more information. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It would be nice to see what the data look like for the oldest people.\n",
    "\n",
    "**Question 9.** Set `sorted_by_age` to a new DataFrame that takes all of the rows from `framingham` and sorts it by age, in *descending* order (oldest at the top).\n",
    "\n",
    "_Hint:_ Use the `sort_values()` function. You'll have to specify two arguments, but it's up to you to figure out what they are... (Try `Shift+Tab` inside the function parentheses!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_by_age = ...\n",
    "sorted_by_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q9\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transforming Data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In question 4, we noticed that the `count` row in the output of `describe()` was not always 500 (the number of rows). If we look at the 12th row of the data, we can see why this is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "framingham.iloc[11]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice the `NaN`s in the `TOTCHOL`, `GLUCOSE`, `HDLC` and `LDLC` columns. `NaN` stands for \"Not a Number\", and indicates that some data are missing for this participant. In this assignment, we will drop the `NaN`s from the `TOTCHOL` column. \n",
    "\n",
    "**Question 10.** Use the `pd.dropna()` function to drop the `NaN`s in the `TOTCHOL` column. You might want to look up the `pandas` documentation to see how to do this. Assign the new dataset to a variable `fr_clean`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fr_clean = ...\n",
    "fr_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q10\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probability refresher"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 11.** Given a fair die, what is the expected value of the die roll? Write out and expand this using expectation notation, where $E(X) = aP(X = a) + bP(X = b) + ... $. What is the probability that $X = E(X)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer in this cell (Remember, you can double click on the text above to see the LaTeX code for expected value notation!)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expected Value vs. Empirical Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `np.mean()` function to find the mean of a column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_chol = np.mean(fr_clean[\"TOTCHOL\"])\n",
    "avg_chol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 12.** Let $C$ be a random variable representing cholesterol in the population. Suppose we know that $C$ has expectation $E(C) = \\mu_C$. \n",
    "\n",
    "*Hint:* If it helps, you can imagine that cholesterol follows a normal distribution with mean $\\mu_C$, but you don't need to know the specific distribution to answer this question.\n",
    "\n",
    "**a.** What is the difference between the expected value of $C$, $E(C)$, and `avg_chol`? (`avg_chol` is called the *empirical mean* of our data, empirical just means based on observations)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer in this cell*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Assume that our sample of people in `framingham` was randomly selected from the population. How confident are you that `avg_chol` is a good estimate of $E(C)$? \n",
    "\n",
    "*Hint:* Calculate a 95\\% confidence interval for `avg_chol` and interpret what that means in terms of confidence in your estimate. You may assume the Central Limit Theorem applies and use $z_{0.975} = 1.96$. Remember to use `fr_clean`!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_low = ...\n",
    "ci_high = ...\n",
    "ci_low, ci_high"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your interpretation of the confidence interval in this cell*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 13.** Two large components of total cholesterol are Low Density Lipoprotein cholesterol (LDL) and High Density Lipoprotein cholesterol (HDL). To assess a patient's cardiovascular risk, a doctor may look at their LDL to HDL ratio. Rather than our random variable $C$, we will now consider two random variables $L$ and $H$, representing LDL and HDL in the population, respectively.\n",
    "\n",
    "Suppose $E(L) = 100$ and $E(H) = 50$. \n",
    "\n",
    "**a.** What is $E(L + H)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your working or explanation here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** Check the documentation in `framdoc.pdf` [here](https://datahub.berkeley.edu/hub/user-redirect/git-pull?repo=https%3A%2F%2Fgithub.com%2Fpublic-health-196%2Fph196-fa20&urlpath=tree%2Fph196-fa20%2Fhw0%2Fframdoc.pdf&branch=master) to find out what the variable names for LDL and HDL cholesterol are in our data. Then, fill in the code below to generate a scatter plot of LDL versus HDL cholesterol using the `matplotlib.pyplot` package (loaded as `plt`). Remember to use `fr_clean`.\n",
    "\n",
    "*Hint:* `x` and `y` should be columns of data to plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(x = ..., y = ..., color=\"blue\")\n",
    "plt.title(\"LDL vs HDL cholesterol\")\n",
    "plt.xlabel(\"Low Density Lipoprotein Cholesterol (mg/dL)\")\n",
    "plt.ylabel(\"High Density Lipoprotein Cholesterol (mg/dL)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**c.** What is $E(\\frac{L}{H})$?\n",
    "\n",
    "*Hint:* Based on your plot in part **b.**, do you think LDL and HDL cholesterol are independent? Why does this matter?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your answer here*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conditional Probability\n",
    "\n",
    "**Question 14.** Imagine we want to devise a very simple test for high blood pressure based on a patient's total cholesterol. Define two random variables $C$, total cholesterol (mg/dL), and an indicator variable $BP$ where $BP = 1$ if the patient has high blood pressure and $BP = 0$ otherwise. We will say the patient has high cholesterol if $C > 200$. Suppose we know the following probabilities:\n",
    "\n",
    "* $P(C > 200 | BP = 1) = 0.8$\n",
    "* $P(C > 200 | BP = 0) = 0.3$\n",
    "* $P(BP = 1) = 0.45$\n",
    "\n",
    "**a.** What is $P(C > 200)$? (Double click on the cell below to write your answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(C > 200) = ...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**b.** What is $P(BP = 1 | C > 200)$?\n",
    "\n",
    "*Hint:* You might find the LaTeX command `\\frac{}{}` helpful. E.g. double click this cell to see the LaTeX code for $\\frac{1}{2}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$P(BP = 1 | C > 200) = ...$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grouping Data\n",
    "\n",
    "So far, we've been dealing with *raw* data--that is, we simply grabbed datapoints that were already in our original set of data without any alterations. Often times, however, we're interested in more complicated queries that involve *groups* of subjects or some function of our original data. \n",
    "\n",
    "For example, let's say that we want to find the average total cholesterol for those above and below the age of 65. Using conditional notation, this is $\\text{TOTCHOL}|\\text{AGE} > 65$. One way to do this is to filter by age group and then find the average cholesterol for each group:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "older_avg = np.average(fr_clean[fr_clean[\"AGE\"] > 65][\"TOTCHOL\"])\n",
    "younger_avg = np.average(fr_clean[fr_clean[\"AGE\"] <= 65][\"TOTCHOL\"])\n",
    "older_avg, younger_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But imagine we were interested in the average total cholesterol not by age *group* but *by age*; it would take forever to write out a line for each age. Moreover, what if the data has billions of rows? It's completely impractical to go through and list out all the possible age values. \n",
    "\n",
    "This is where grouping comes in. We can choose a column to *group by* (in this case, we want to group rows by `age`), and an *aggregation function* (in this case, we want to take the mean of the total cholestoral per age group) that we can apply to each group."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_and_chol = fr_clean[[\"AGE\", \"TOTCHOL\"]]\n",
    "chol_grouped_by_age = age_and_chol.groupby(\"AGE\").mean()\n",
    "chol_grouped_by_age"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 15.** Suppose we want to perform calculations on our data to extract further insight that isn't included explicitly. \n",
    "\n",
    "Mean arterial pressure ($MAP$) is a better clinical indicator of tissue perfusion than systolic/diastolic blood pressure. Find the average $MAP|AGE$ (average $MAP$ grouped by age), where $MAP$ is defined as \n",
    "\n",
    "$$MAP = \\dfrac{SYSBP + 2 \\cdot DIABP}{3}$$\n",
    "\n",
    "and assign the resulting DataFrame (with `AGE` in the index and average `MAP` as a column) to `map_grouped_by_age`. **Remember to use `fr_clean` instead of `framingham`.**\n",
    "\n",
    "*Hint 1:* Create a new column called `MAP` in `fr_clean`. Remember that you can apply arithmetic arraywise operations to columns (i.e. you can add two columns together like vectors) to make this easier: `np.array([1, 2]) + np.array([3, 4]) = np.array([4, 6])`.\n",
    "\n",
    "*Hint 2:* Select the `AGE` and `MAP` column, then group by the age using the syntax above.\n",
    "\n",
    "You might get a warning (not an error), and this is expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr_clean[\"MAP\"] = ...\n",
    "map_grouped_by_age = ...\n",
    "map_grouped_by_age.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q15\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing Data\n",
    "\n",
    "Visualizing our results is often crucial in drawing conclusions. Here are examples of a few types of common plots made using `matplotlib`. To make a histogram, use `plt.hist()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Histogram of ages in the study\n",
    "plt.hist(fr_clean[\"AGE\"], density=True)\n",
    "plt.title(\"Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show();  # Always add plt.show after each set of plot code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's really easy and convenient in Python to customize our plots (note the titles and axes labels!). For example, we can adjust the bin sizes like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_bins = np.arange(35, 85, 5) # [35 40 45 50 55 60 65 70 75 80]\n",
    "print(\"Custom bins:\", custom_bins)\n",
    "plt.hist(fr_clean[\"AGE\"] , density=True, bins=custom_bins)\n",
    "plt.title(\"Age\")\n",
    "plt.xlabel(\"Age\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In question 13 we created a scatter plot using `plt.scatter()`. We can also overlay multiple sets of plots on the same graph. Here, we plot the average systolic BP, diastolic BP, and MAP per age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bp_grouped = fr_clean[[\"AGE\", \"SYSBP\", \"DIABP\", \"MAP\"]].groupby(\"AGE\").mean()\n",
    "plt.scatter(x=bp_grouped.index, y=bp_grouped[\"SYSBP\"], color=\"blue\", label=\"SYSBP\")\n",
    "plt.scatter(x=bp_grouped.index, y=bp_grouped[\"DIABP\"], color=\"orange\", label=\"DIABP\")\n",
    "plt.scatter(x=bp_grouped.index, y=bp_grouped[\"MAP\"], color=\"green\", label=\"MAP\")\n",
    "plt.legend() # Shows legend based on label parameter in `plt.scatter` calls above\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try making our own histogram.\n",
    "\n",
    "**Question 16.** Using the `fr_clean` DataFrame, create a double overlayed histogram, one for the distribution of the average cholesterol of people over the age of 65 and another for the people 65 years of age or younger. Distinguish the two histograms with different colors, adding proper titles, axes labels, and legends. Use `alpha=0.5` as an argument for `plt.hist()` to create transparent plots.\n",
    "\n",
    "*Hint 1:* First create two arrays of cholesterol, filtered by age group.\n",
    "\n",
    "*Hint 2:* Look at the above examples on how to format titles, axes, and legends properly. \n",
    "\n",
    "*Hint 3:* Don't forget to add `density=True`, `label`s, and `alpha` to the `plt.hist()` calls!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "older_chol = ...\n",
    "younger_chol = ...\n",
    "\n",
    "plt.hist(...)\n",
    "plt.hist(...)\n",
    "# Add your title, axis labels and legend here\n",
    "plt.show();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A very small model\n",
    "\n",
    "The `scikit-learn` package is very widely used in machine learning to fit models. In this question we will fit a very simple linear model with one predictor variable. Suppose we want to predict a patient's cholesterol based only on whether they smoke. This isn't a realistic scenario, but in this exercise we want to get comfortable fitting models using `scikit-learn` and refresh your memory on interpreting regression coefficients. In the next homework you will get practice fitting more complex models and you will see that the syntax is very similar!\n",
    "\n",
    "**Question 17.** Use the `sklearn.linear_model` module to write a function `fit_lm` that takes in:\n",
    "\n",
    "- `feature` (`pd.DataFrame`): a dataframe with the single variable you want to use as a predictor\n",
    "- `outcome` (`np.array` or `pd.Series`): the outcome you want to predict\n",
    "\n",
    "and returns a `sklearn.linear_model.LinearRegression` model object representing the linear model:\n",
    "\n",
    "$$\\text{outcome} = \\beta_0 + \\beta_1\\text{feature} + \\epsilon$$\n",
    "\n",
    "*Note:* If you are used to working in R, this function would be the equivalent of `lm(outcome ~ feature)`\n",
    "\n",
    "*Hint:* Look at the documentation for the `sklearn.linear_model.LinearRegression()` function [here](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html) to understand how to create and fit a model. We have included the relevant `import` statement below, but you'll need to know how to do this for future homeworks.\n",
    "\n",
    "*Hint:* Remember to call the `fit(...,...)` function inside your function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def fit_lm(feature, outcome):\n",
    "    # These lines check that your inputs are of the correct type.\n",
    "    # Do not remove them.\n",
    "    assert type(feature) == pd.DataFrame\n",
    "    assert type(outcome) in (pd.Series, np.array)\n",
    "    \n",
    "    # Fill in your code here\n",
    "    model = ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q17\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 18.** Use your `fit_lm` function to fit a model with the outcome `TOTCHOL` and a single feature `CURSMOKE`. Use the `fr_clean` dataframe. \n",
    "\n",
    "Assign the intercept of your model to a variable `intercept` and the regression coefficient on `CURSMOKE` to `coeff`.\n",
    "\n",
    "*Hint 1:* Remember that you need `feature` to be of type `pd.DataFrame` and `outcome` should be `pd.Series` or `np.array`. What is the difference between `type(fr_clean[[\"CURSMOKE\"]])` and `type(fr_clean[\"CURSMOKE\"])`?\n",
    "\n",
    "*Hint 2:* Go back to the documentation for the `LinearRegression()` function. What attributes does your model have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ...\n",
    "coeff = ...\n",
    "intercept = ...\n",
    "intercept, coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = ok.grade(\"q18\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 19.** Explain in your own words what each of the coefficients in this model represents. \n",
    "\n",
    "*Hint:* What is the mean `TOTCHOL` in this dataset? What is the mean of `TOTCHOL|CURSMOKE = 1`?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Write your solution here. You may want to add a code cell below this to find means if you are using the hint.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission\n",
    "Congrats, you're done with your first homework! Once you're finished, follow these steps to save your work and submit:\n",
    "\n",
    "* Make sure you've run all of your cells: Cell > Run all\n",
    "* Save your work: File > Save and checkpoint\n",
    "* Download your notebook as a PDF: File > Download as > PDF via HTML (.pdf).  \n",
    "* Submit your PDF on Gradescope. Make sure to tag your submission correctly corresponding to the questions on each page. Please tag the autograder output along with your code or written response.\n",
    "\n",
    "You may submit as many times as you want up until the deadline!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
